\chapter{Introduction} \label{chap:intro}

Modern computing is evolving from an era of isolated, high-performance machines toward a landscape defined by massively interconnected ensembles of devices. This transition is evident in global \ac{IoT} sensor networks and smart city infrastructures~\cite{DBLP:journals/internet/AguzziCPV22}, where the focus has shifted from individual computation to collective coordination. These \acp{CAS}~\cite{DBLP:conf/birthday/BucchiaroneM19} comprehend vast numbers of agents that adapt their behavior based on local interactions and environmental fluctuations. As these systems scale toward millions of nodes, traditional `command-and-control' architectures become untenable due to latency, bandwidth constraints, and single-point-of-failure risks. Consequently, there is a pressing need for research into decentralized coordination, where collective intelligence emerges from local interactions rather than global oversight.

The verification and engineering of such systems remain daunting tasks due to inherent complexity and emergent behaviors. A spectrum of methods is typically employed to address these challenges, including formal analysis~\cite{DBLP:journals/ras/KonurDF12}, \ac{HIL} testing~\cite{Sende2024}, and simulation. While simulation is a critical tool for navigating these complexities, a significant trade-off exists between realism and scalability. Lower-fidelity, large-scale simulators are widely used~\cite{DBLP:journals/computation/Calderon-ArceBS22}, yet they often overlook the high-fidelity physical dynamics and environmental interactions necessary for reliable deployment. This gap exists largely because developing high-fidelity simulators from scratch is resource-intensive, requiring specialized expertise in physics and rendering that often falls outside the traditional \ac{CAS} research domain.

This thesis addresses the engineering disconnect between abstract coordination models, such as \ac{AC}, and the practical requirements of 3D environments. The work proposes leveraging modern game development platforms to bridge the `reality gap' that frequently complicates the translation of algorithms onto physical hardware. By exploring the integration of the \ac{AC} implementation Collektive~\cite{DBLP:conf/acsos/Cortecchia24} with the Unity engine, this research investigates how automated development workflows and robust physics engines can provide a reliable infrastructure for the next generation of collective system design.

\section{Motivation: Swarm Behavior}

The natural world provides the strongest precedent for resilient, decentralized coordination. From the synchronized flashing of fireflies to the architectural precision of termite mounds and the fluid motion of starling murmurings, biological systems exhibit an efficiency that classical engineering often struggles to replicate. These phenomena, categorized as \ac{SI}~\cite{Bonabeau_Dorigo_Theraulaz_1999}, arise from simple agents following localized rules. In a natural swarm, intelligence is inherently distributed; while individual agents possess only a partial perception of their surroundings, the collective can solve high-order problems such as finding food or evading predators.

From an engineering perspective, these biological systems offer three indispensable properties. First, the absence of a central controller ensures that the loss of individual units does not compromise the overall mission~\cite[pp.~6-11]{Bonabeau_Dorigo_Theraulaz_1999}. Second, the systems are naturally scalable, as the logic governing ten agents remains functional for ten thousand due to the localized nature of interactions. Finally, swarms exhibit remarkable robustness, autonomously re-configuring their behavior in response to external stimuli~\cite[pp.~25-36]{Bonabeau_Dorigo_Theraulaz_1999}. As these characteristics are ported into the digital domain through paradigms like \ac{AC}, a significant translation gap becomes apparent. While mathematical models for collective logic are maturing, the tools to test them in high-fidelity environments remain fragmented.

\section{Problem Statement: Engineering Challenges in Simulation}

While simulation scalability has been widely explored, high-fidelity simulation introduces hard constraints that mathematical rigor often ignores. Physical factors such as collisions, gravity, and friction are essential for a realistic cooperative swarm, yet traditional simulators often prioritize agent count at the expense of this environmental complexity. This leads to a discrepancy between simulation and reality that impede practical application. Game engines address the physics challenge by providing specialized environments designed to compute physical interactions with high rigor. However, the core problem lies in the architectural alignment between these two worlds.

Bridging high-level coordination with game-engine physics involves several key hurdles. One primary issue is synchronism; collective programming models typically rely on discrete logical steps, whereas game engines operate on a continuous, high-frequency `tick'. There is also a challenge of abstraction, as collective models often treat agents as dimensionless points in space, while high-fidelity environments represent them as complex entities with mass, inertia, and physical bounds. Finally, there is the requirement of scalability; even with increased fidelity, a simulator must remain performant enough to represent a sufficient number of nodes to maintain the `collective' nature of the experiment.
